{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/Cellar/apache-spark/2.4.4/libexec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bharaths-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test_new</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11217b210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer, RegexTokenizer, StopWordsRemover, IDF, MinHashLSH\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.sql.functions import explode, col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"test_new\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the drive stats csv files into the spark dataframe\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"/Users/bharathsurianarayanan/Downloads/drive_stats_2019_Q1/*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- serial_number: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- capacity_bytes: string (nullable = true)\n",
      " |-- failure: string (nullable = true)\n",
      " |-- smart_1_normalized: string (nullable = true)\n",
      " |-- smart_1_raw: string (nullable = true)\n",
      " |-- smart_2_normalized: string (nullable = true)\n",
      " |-- smart_2_raw: string (nullable = true)\n",
      " |-- smart_3_normalized: string (nullable = true)\n",
      " |-- smart_3_raw: string (nullable = true)\n",
      " |-- smart_4_normalized: string (nullable = true)\n",
      " |-- smart_4_raw: string (nullable = true)\n",
      " |-- smart_5_normalized: string (nullable = true)\n",
      " |-- smart_5_raw: string (nullable = true)\n",
      " |-- smart_7_normalized: string (nullable = true)\n",
      " |-- smart_7_raw: string (nullable = true)\n",
      " |-- smart_8_normalized: string (nullable = true)\n",
      " |-- smart_8_raw: string (nullable = true)\n",
      " |-- smart_9_normalized: string (nullable = true)\n",
      " |-- smart_9_raw: string (nullable = true)\n",
      " |-- smart_10_normalized: string (nullable = true)\n",
      " |-- smart_10_raw: string (nullable = true)\n",
      " |-- smart_11_normalized: string (nullable = true)\n",
      " |-- smart_11_raw: string (nullable = true)\n",
      " |-- smart_12_normalized: string (nullable = true)\n",
      " |-- smart_12_raw: string (nullable = true)\n",
      " |-- smart_13_normalized: string (nullable = true)\n",
      " |-- smart_13_raw: string (nullable = true)\n",
      " |-- smart_15_normalized: string (nullable = true)\n",
      " |-- smart_15_raw: string (nullable = true)\n",
      " |-- smart_16_normalized: string (nullable = true)\n",
      " |-- smart_16_raw: string (nullable = true)\n",
      " |-- smart_17_normalized: string (nullable = true)\n",
      " |-- smart_17_raw: string (nullable = true)\n",
      " |-- smart_22_normalized: string (nullable = true)\n",
      " |-- smart_22_raw: string (nullable = true)\n",
      " |-- smart_23_normalized: string (nullable = true)\n",
      " |-- smart_23_raw: string (nullable = true)\n",
      " |-- smart_24_normalized: string (nullable = true)\n",
      " |-- smart_24_raw: string (nullable = true)\n",
      " |-- smart_168_normalized: string (nullable = true)\n",
      " |-- smart_168_raw: string (nullable = true)\n",
      " |-- smart_170_normalized: string (nullable = true)\n",
      " |-- smart_170_raw: string (nullable = true)\n",
      " |-- smart_173_normalized: string (nullable = true)\n",
      " |-- smart_173_raw: string (nullable = true)\n",
      " |-- smart_174_normalized: string (nullable = true)\n",
      " |-- smart_174_raw: string (nullable = true)\n",
      " |-- smart_177_normalized: string (nullable = true)\n",
      " |-- smart_177_raw: string (nullable = true)\n",
      " |-- smart_179_normalized: string (nullable = true)\n",
      " |-- smart_179_raw: string (nullable = true)\n",
      " |-- smart_181_normalized: string (nullable = true)\n",
      " |-- smart_181_raw: string (nullable = true)\n",
      " |-- smart_182_normalized: string (nullable = true)\n",
      " |-- smart_182_raw: string (nullable = true)\n",
      " |-- smart_183_normalized: string (nullable = true)\n",
      " |-- smart_183_raw: string (nullable = true)\n",
      " |-- smart_184_normalized: string (nullable = true)\n",
      " |-- smart_184_raw: string (nullable = true)\n",
      " |-- smart_187_normalized: string (nullable = true)\n",
      " |-- smart_187_raw: string (nullable = true)\n",
      " |-- smart_188_normalized: string (nullable = true)\n",
      " |-- smart_188_raw: string (nullable = true)\n",
      " |-- smart_189_normalized: string (nullable = true)\n",
      " |-- smart_189_raw: string (nullable = true)\n",
      " |-- smart_190_normalized: string (nullable = true)\n",
      " |-- smart_190_raw: string (nullable = true)\n",
      " |-- smart_191_normalized: string (nullable = true)\n",
      " |-- smart_191_raw: string (nullable = true)\n",
      " |-- smart_192_normalized: string (nullable = true)\n",
      " |-- smart_192_raw: string (nullable = true)\n",
      " |-- smart_193_normalized: string (nullable = true)\n",
      " |-- smart_193_raw: string (nullable = true)\n",
      " |-- smart_194_normalized: string (nullable = true)\n",
      " |-- smart_194_raw: string (nullable = true)\n",
      " |-- smart_195_normalized: string (nullable = true)\n",
      " |-- smart_195_raw: string (nullable = true)\n",
      " |-- smart_196_normalized: string (nullable = true)\n",
      " |-- smart_196_raw: string (nullable = true)\n",
      " |-- smart_197_normalized: string (nullable = true)\n",
      " |-- smart_197_raw: string (nullable = true)\n",
      " |-- smart_198_normalized: string (nullable = true)\n",
      " |-- smart_198_raw: string (nullable = true)\n",
      " |-- smart_199_normalized: string (nullable = true)\n",
      " |-- smart_199_raw: string (nullable = true)\n",
      " |-- smart_200_normalized: string (nullable = true)\n",
      " |-- smart_200_raw: string (nullable = true)\n",
      " |-- smart_201_normalized: string (nullable = true)\n",
      " |-- smart_201_raw: string (nullable = true)\n",
      " |-- smart_218_normalized: string (nullable = true)\n",
      " |-- smart_218_raw: string (nullable = true)\n",
      " |-- smart_220_normalized: string (nullable = true)\n",
      " |-- smart_220_raw: string (nullable = true)\n",
      " |-- smart_222_normalized: string (nullable = true)\n",
      " |-- smart_222_raw: string (nullable = true)\n",
      " |-- smart_223_normalized: string (nullable = true)\n",
      " |-- smart_223_raw: string (nullable = true)\n",
      " |-- smart_224_normalized: string (nullable = true)\n",
      " |-- smart_224_raw: string (nullable = true)\n",
      " |-- smart_225_normalized: string (nullable = true)\n",
      " |-- smart_225_raw: string (nullable = true)\n",
      " |-- smart_226_normalized: string (nullable = true)\n",
      " |-- smart_226_raw: string (nullable = true)\n",
      " |-- smart_231_normalized: string (nullable = true)\n",
      " |-- smart_231_raw: string (nullable = true)\n",
      " |-- smart_232_normalized: string (nullable = true)\n",
      " |-- smart_232_raw: string (nullable = true)\n",
      " |-- smart_233_normalized: string (nullable = true)\n",
      " |-- smart_233_raw: string (nullable = true)\n",
      " |-- smart_235_normalized: string (nullable = true)\n",
      " |-- smart_235_raw: string (nullable = true)\n",
      " |-- smart_240_normalized: string (nullable = true)\n",
      " |-- smart_240_raw: string (nullable = true)\n",
      " |-- smart_241_normalized: string (nullable = true)\n",
      " |-- smart_241_raw: string (nullable = true)\n",
      " |-- smart_242_normalized: string (nullable = true)\n",
      " |-- smart_242_raw: string (nullable = true)\n",
      " |-- smart_250_normalized: string (nullable = true)\n",
      " |-- smart_250_raw: string (nullable = true)\n",
      " |-- smart_251_normalized: string (nullable = true)\n",
      " |-- smart_251_raw: string (nullable = true)\n",
      " |-- smart_252_normalized: string (nullable = true)\n",
      " |-- smart_252_raw: string (nullable = true)\n",
      " |-- smart_254_normalized: string (nullable = true)\n",
      " |-- smart_254_raw: string (nullable = true)\n",
      " |-- smart_255_normalized: string (nullable = true)\n",
      " |-- smart_255_raw: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the schema of the loaded dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+------------------+--------+\n",
      "|      date| serial_number|               model|smart_1_normalized|features|\n",
      "+----------+--------------+--------------------+------------------+--------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|               117| [117.0]|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|                80|  [80.0]|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|                83|  [83.0]|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|                81|  [81.0]|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|               100| [100.0]|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|                75|  [75.0]|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|                83|  [83.0]|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|                83|  [83.0]|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|                78|  [78.0]|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|                77|  [77.0]|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|               117| [117.0]|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|                81|  [81.0]|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|                74|  [74.0]|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|                80|  [80.0]|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|                78|  [78.0]|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|               100| [100.0]|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|               100| [100.0]|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|               100| [100.0]|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|               100| [100.0]|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|               100| [100.0]|\n",
      "+----------+--------------+--------------------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- serial_number: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- smart_1_normalized: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "#convert smart_1_normalized from string to Integer type \n",
    "df = df.withColumn(\"smart_1_normalized\", df[\"smart_1_normalized\"].cast(IntegerType()))\n",
    "# vectorize the column smart_1_normalized and store the vector in a column named features\n",
    "vecAssembler=VectorAssembler(inputCols=[\"smart_1_normalized\"],outputCol=\"features\")\n",
    "# skip invalid values\n",
    "new_df=vecAssembler.setHandleInvalid('skip').transform(df)\n",
    "# lets take only the columns necessary for part a) i.e kmeans with respect to smart_1_normalized column\n",
    "temp_df=new_df.select('date','serial_number','model','smart_1_normalized','features')\n",
    "temp_df.show()\n",
    "temp_df.printSchema()\n",
    "\n",
    "temp_df=temp_df.where(F.col('features').isNotNull())\n",
    "# temp_df=temp_df.select('features')\n",
    "# temp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=2, seed=1)  # 2 clusters here\n",
    "model = kmeans.fit(temp_df.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+------------------+--------+----------+\n",
      "|      date| serial_number|               model|smart_1_normalized|features|prediction|\n",
      "+----------+--------------+--------------------+------------------+--------+----------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|               117| [117.0]|         1|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|                80|  [80.0]|         0|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|                83|  [83.0]|         0|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|                81|  [81.0]|         0|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|               100| [100.0]|         1|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|                75|  [75.0]|         0|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|                83|  [83.0]|         0|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|                83|  [83.0]|         0|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|                78|  [78.0]|         0|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|                77|  [77.0]|         0|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|               117| [117.0]|         1|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|                81|  [81.0]|         0|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|                74|  [74.0]|         0|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|                80|  [80.0]|         0|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|                78|  [78.0]|         0|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|               100| [100.0]|         1|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|               100| [100.0]|         1|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|               100| [100.0]|         1|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|               100| [100.0]|         1|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|               100| [100.0]|         1|\n",
      "+----------+--------------+--------------------+------------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed=model.transform(temp_df)\n",
    "transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.801856063520587\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(transformed)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+------------------+--------+----------+-----------+\n",
      "|      date| serial_number|               model|smart_1_normalized|features|prediction|      label|\n",
      "+----------+--------------+--------------------+------------------+--------+----------+-----------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|               117| [117.0]|         1|    Anomaly|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|                80|  [80.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|                83|  [83.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|                81|  [81.0]|         0|Not Anomaly|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|               100| [100.0]|         1|    Anomaly|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|                75|  [75.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|                83|  [83.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|                83|  [83.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|                78|  [78.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|                77|  [77.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|               117| [117.0]|         1|    Anomaly|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|                81|  [81.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|                74|  [74.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|                80|  [80.0]|         0|Not Anomaly|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|                78|  [78.0]|         0|Not Anomaly|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|               100| [100.0]|         1|    Anomaly|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|               100| [100.0]|         1|    Anomaly|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|               100| [100.0]|         1|    Anomaly|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|               100| [100.0]|         1|    Anomaly|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|               100| [100.0]|         1|    Anomaly|\n",
      "+----------+--------------+--------------------+------------------+--------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "#generating labels based on the predicted values, if predicted value is 1 then it is an Anomaly else it is not an Anomaly\n",
    "# this \n",
    "df_temp = transformed.withColumn(\n",
    "    'label',\n",
    "    F.when((F.col(\"prediction\") == 1), 'Anomaly')\\\n",
    "    .otherwise(\"Not Anomaly\")\n",
    ")\n",
    "\n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# part a) k means using smart_1_normalized column\n",
    "#scaling the features, to the range [0,1] so as to improve the accuracy of k means\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features\",\\\n",
    "         outputCol=\"scaledFeatures\")\n",
    "scalerModel =  scaler.fit(temp_df.select(\"features\"))\n",
    "scaledData = scalerModel.transform(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- serial_number: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- smart_1_normalized: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaledFeatures: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaledData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+------------------+--------+--------------------+\n",
      "|      date| serial_number|               model|smart_1_normalized|features|      scaledFeatures|\n",
      "+----------+--------------+--------------------+------------------+--------+--------------------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|               117| [117.0]|[0.4503311258278146]|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|                80|  [80.0]|[0.2052980132450331]|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|                83|  [83.0]|[0.2251655629139073]|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|                81|  [81.0]|[0.2119205298013245]|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|               100| [100.0]|[0.33774834437086...|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|                75|  [75.0]|[0.17218543046357...|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|                83|  [83.0]|[0.2251655629139073]|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|                83|  [83.0]|[0.2251655629139073]|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|                78|  [78.0]|[0.19205298013245...|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|                77|  [77.0]|[0.18543046357615...|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|               117| [117.0]|[0.4503311258278146]|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|                81|  [81.0]|[0.2119205298013245]|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|                74|  [74.0]|[0.16556291390728...|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|                80|  [80.0]|[0.2052980132450331]|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|                78|  [78.0]|[0.19205298013245...|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|               100| [100.0]|[0.33774834437086...|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|               100| [100.0]|[0.33774834437086...|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|               100| [100.0]|[0.33774834437086...|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|               100| [100.0]|[0.33774834437086...|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|               100| [100.0]|[0.33774834437086...|\n",
      "+----------+--------------+--------------------+------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the scaled data\n",
    "scaledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "#build the k means model, k specifies the number of clusters while seed is a pseudorandom number\n",
    "#for different values of \"seed\" differnt initial centroids are chosen\n",
    "#the value of k was chosen because for different values of k the clustering silhouettte was calculated\n",
    "#the silhouette measure was highest for k=49 , which is also the number of unique models, thus this k was settled upoon\n",
    "kmeans = KMeans(k=49, seed=1)  # 2 clusters here\n",
    "model = kmeans.fit(scaledData.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+------------------+--------+--------------------+----------+\n",
      "|      date| serial_number|               model|smart_1_normalized|features|      scaledFeatures|prediction|\n",
      "+----------+--------------+--------------------+------------------+--------+--------------------+----------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|               117| [117.0]|[0.4503311258278146]|        21|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|                80|  [80.0]|[0.2052980132450331]|         7|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|                83|  [83.0]|[0.2251655629139073]|        11|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|                81|  [81.0]|[0.2119205298013245]|         4|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|               100| [100.0]|[0.33774834437086...|         1|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|                75|  [75.0]|[0.17218543046357...|         8|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|                83|  [83.0]|[0.2251655629139073]|        11|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|                83|  [83.0]|[0.2251655629139073]|        11|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|                78|  [78.0]|[0.19205298013245...|        17|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|                77|  [77.0]|[0.18543046357615...|         9|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|               117| [117.0]|[0.4503311258278146]|        21|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|                81|  [81.0]|[0.2119205298013245]|         4|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|                74|  [74.0]|[0.16556291390728...|        15|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|                80|  [80.0]|[0.2052980132450331]|         7|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|                78|  [78.0]|[0.19205298013245...|        17|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|               100| [100.0]|[0.33774834437086...|         1|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|               100| [100.0]|[0.33774834437086...|         1|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|               100| [100.0]|[0.33774834437086...|         1|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|               100| [100.0]|[0.33774834437086...|         1|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|               100| [100.0]|[0.33774834437086...|         1|\n",
      "+----------+--------------+--------------------+------------------+--------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform the data based on the generated model\n",
    "scaled_transformed=model.transform(scaledData)\n",
    "scaled_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.9683050263733727\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "#evaluate the generated model using the CLustering evaluator which finds the silhouette with the squared \n",
    "# euclidian distance\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "#the silouette measure ranges from -1 to 1 , the closer it is to 1, the more similar are points within the cluster\n",
    "# the closer it is to -1 the more dissimilar are the points within the cluster\n",
    "silhouette = evaluator.evaluate(scaled_transformed)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[363763,\n",
       " 2194364,\n",
       " 442079,\n",
       " 58903,\n",
       " 616376,\n",
       " 387173,\n",
       " 97029,\n",
       " 486657,\n",
       " 153994,\n",
       " 244531,\n",
       " 777905,\n",
       " 1055399,\n",
       " 138611,\n",
       " 43465,\n",
       " 36550,\n",
       " 123168,\n",
       " 48910,\n",
       " 307408,\n",
       " 38903,\n",
       " 194125,\n",
       " 779,\n",
       " 438859,\n",
       " 97006,\n",
       " 291628,\n",
       " 22885,\n",
       " 294298,\n",
       " 36401,\n",
       " 146362,\n",
       " 109119,\n",
       " 145712,\n",
       " 55447,\n",
       " 36522,\n",
       " 54930,\n",
       " 36251,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of points in each cluster\n",
    "# sparse number of points in a cluster means they're probably outliers\n",
    "# from the results we see that the first cluster has > 99% of the data, hence the data in  the cluster with size =779\n",
    "# is the outlier data cluster\n",
    "summary=model.summary\n",
    "summary.clusterSizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------+--------+\n",
      "|      date| serial_number|               model|failure|features|\n",
      "+----------+--------------+--------------------+-------+--------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|      0|   [0.0]|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|      0|   [0.0]|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|      0|   [0.0]|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|      0|   [0.0]|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|      0|   [0.0]|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|      0|   [0.0]|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|      0|   [0.0]|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|      0|   [0.0]|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|      0|   [0.0]|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|      0|   [0.0]|\n",
      "+----------+--------------+--------------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- serial_number: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- failure: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# part b) k means with the annualized failure rate column\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#convert failure from string to Integer type \n",
    "df_failures = df.withColumn(\"failure\", df[\"failure\"].cast(IntegerType()))\n",
    "# vectorize the column smart_1_normalized and store the vector in a column named features\n",
    "vecAssembler=VectorAssembler(inputCols=[\"failure\"],outputCol=\"features\")\n",
    "# skip invalid values\n",
    "new_df_failures=vecAssembler.setHandleInvalid('skip').transform(df_failures)\n",
    "# lets take only the columns necessary for part a) i.e kmeans with respect to smart_1_normalized column\n",
    "temp_df_failures=new_df_failures.select('date','serial_number','model','failure','features')\n",
    "temp_df_failures.show()\n",
    "temp_df_failures.printSchema()\n",
    "\n",
    "temp_df_failures=temp_df_failures.where(F.col('features').isNotNull())\n",
    "# temp_df=temp_df.select('features')\n",
    "# temp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans_failures = KMeans(k=49, seed=1)  # 2 clusters here\n",
    "model_failures = kmeans_failures.fit(temp_df_failures.select('features'))\n",
    "temp=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------+--------+----------+\n",
      "|      date| serial_number|               model|failure|features|prediction|\n",
      "+----------+--------------+--------------------+-------+--------+----------+\n",
      "|2019-03-05|      Z305B2QN|         ST4000DM000|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV0XJQ4|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV0XJQ3|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV0XJQ0|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|PL1331LAHG1S4H|HGST HMS5C4040ALE640|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZA16NQJR|        ST8000NM0055|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV02XWG|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV1CSVX|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV02XWA|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZA18CEBS|        ST8000NM0055|      0|   [0.0]|         0|\n",
      "|2019-03-05|      Z305DEMG|         ST4000DM000|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZA130TTW|         ST8000DM002|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV1CSVV|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZA18CEBF|        ST8000NM0055|      0|   [0.0]|         0|\n",
      "|2019-03-05|      ZJV02XWV|       ST12000NM0007|      0|   [0.0]|         0|\n",
      "|2019-03-05|PL2331LAG9TEEJ|HGST HMS5C4040ALE640|      0|   [0.0]|         0|\n",
      "|2019-03-05|PL2331LAH3WYAJ|HGST HMS5C4040BLE640|      0|   [0.0]|         0|\n",
      "|2019-03-05|PL1331LAHG53YH|HGST HMS5C4040BLE640|      0|   [0.0]|         0|\n",
      "|2019-03-05|  88Q0A0LGF97G| TOSHIBA MG07ACA14TA|      0|   [0.0]|         0|\n",
      "|2019-03-05|PL2331LAHDUVVJ|HGST HMS5C4040BLE640|      0|   [0.0]|         0|\n",
      "+----------+--------------+--------------------+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_failures=model_failures.transform(temp_df_failures)\n",
    "transformed_failures.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluator = ClusteringEvaluator()\n",
    "#the silouette measure ranges from -1 to 1 , the closer it is to 1, the more similar are points within the cluster\n",
    "# the closer it is to -1 the more dissimilar are the points within the cluster\n",
    "silhouette = evaluator.evaluate(transformed_failures)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary for a model\n",
    "summary=model_failures.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9576602,\n",
       " 444,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of points in each cluster\n",
    "# sparse number of points in a cluster means they're probably outliers\n",
    "# from the results we see that the first cluster has > 99% of the data, hence the data in all the clusters other than\n",
    "# the first cluster are outliers, infact no other cluster has any other element which shows how tight each of the points\n",
    "# are\n",
    "summary.clusterSizes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
